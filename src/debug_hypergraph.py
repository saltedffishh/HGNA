# src/debug_hypergraph.py
"""
Hypergraph sanity check (operator version)

Checks:
1. Structure sanity (H shape / sparsity)
2. Degree statistics (dv / de)
3. Cell participation distribution
4. Program size distribution
5. Biological enrichment using cell.annotation
"""

import argparse
import numpy as np
import pandas as pd
import scipy.sparse as sp

from utils.paths import get_experiments_root
from utils.io import load_sparse_matrix
from datasets_loader_bar import load_dataset_pairs
from utils.io import load_expr_matrix


# -------------------------------------------------
# Check 1: åŸºæœ¬ç»“æ„
# -------------------------------------------------
def check_structure(H):
    print("\n=== Check 1: Hypergraph Structure ===")
    print(f"H shape      : {H.shape}")
    print(f"H nnz        : {H.nnz}")
    print(f"H is sparse  : {sp.issparse(H)}")

    assert sp.issparse(H), "âŒ H å¿…é¡»æ˜¯ç¨€ç–çŸ©é˜µ"
    assert H.shape[0] > H.shape[1], "âŒ modules æ•°å¼‚å¸¸å¤§ï¼Ÿ"

    print("âœ… Check 1 passed")


# -------------------------------------------------
# Check 2: åº¦åˆ†å¸ƒ
# -------------------------------------------------
def check_degrees(dv, de):
    print("\n=== Check 2: Degree Distributions ===")

    print("Cell degree (dv):")
    print(pd.Series(dv).describe())

    print("\nProgram degree (de):")
    print(pd.Series(de).describe())

    print("Zero dv count:", np.sum(dv == 0))
    print("Zero de count:", np.sum(de == 0))

    print("âœ… Check 2 finished (éœ€äººå·¥åˆ¤æ–­æ˜¯å¦åˆç†)")


# -------------------------------------------------
# Check 3: cell å‚ä¸ program æ•°
# -------------------------------------------------
def check_cell_participation(H):
    print("\n=== Check 3: Cell Participation ===")

    counts = np.array((H > 0).sum(axis=1)).flatten()
    stats = pd.Series(counts).describe()
    print(stats)

    print(
        f"Cells with zero programs: {np.sum(counts == 0)}"
    )

    print("âœ… Check 3 finished")


# -------------------------------------------------
# Check 4: program è¦†ç›–ç»†èƒæ•°
# -------------------------------------------------
def check_program_sizes(H):
    print("\n=== Check 4: Program Sizes ===")

    sizes = np.array((H > 0).sum(axis=0)).flatten()
    stats = pd.Series(sizes).describe()
    print(stats)

    print("Smallest programs:", np.sort(sizes)[:5])
    print("Largest programs :", np.sort(sizes)[-5:])

    print("âœ… Check 4 finished")


# -------------------------------------------------
# Check 5: ç”Ÿç‰©å­¦ä¸€è‡´æ€§ï¼ˆprogram å¯Œé›†ï¼‰
# -------------------------------------------------
def check_biological_enrichment(H, meta, top_k=3):
    print("\n=== Check 5: Biological Enrichment ===")

    assert "cell.annotation" in meta.columns, \
        "âŒ metadata ä¸­ç¼ºå°‘ cell.annotation"

    H_bin = (H > 0).astype(int)

    for m in range(min(H.shape[1], top_k)):
        cells_in_prog = np.where(H_bin[:, m].toarray().flatten())[0]
        if len(cells_in_prog) == 0:
            continue

        print(f"\nProgram {m}: size = {len(cells_in_prog)}")
        print(
            meta.iloc[cells_in_prog]["cell.annotation"]
            .value_counts(normalize=True)
            .head()
        )

    print("âœ… Check 5 finished")


# -------------------------------------------------
# Main
# -------------------------------------------------
def main():
    parser = argparse.ArgumentParser(
        description="Hypergraph sanity check (operator version)"
    )
    parser.add_argument(
        "--dataset",
        type=str,
        required=True,
        help="æ•°æ®é›†åç§°ï¼ˆç”¨äº metadataï¼‰"
    )
    parser.add_argument(
        "--exp_name",
        type=str,
        required=True,
        help="experiments/ ä¸‹å®éªŒç›®å½•å"
    )
    parser.add_argument(
        "--stage",
        type=int,
        default=0,
        help="æ£€æŸ¥ç¬¬å‡ ä¸ª stage"
    )

    args = parser.parse_args()

    # -----------------------------
    # å®éªŒç›®å½•
    # -----------------------------
    exp_dir = get_experiments_root() / args.exp_name
    assert exp_dir.exists(), f"âŒ å®éªŒç›®å½•ä¸å­˜åœ¨: {exp_dir}"
    print(f"ğŸ“‚ ä½¿ç”¨å®éªŒç›®å½•: {exp_dir}")

    hyper_dir = exp_dir / "hypergraphs"

    # -----------------------------
    # è¯»å–è¶…å›¾
    # -----------------------------
    H = load_sparse_matrix(
        hyper_dir / f"H_stage{args.stage}.npz"
    )
    dv = np.load(hyper_dir / f"dv_stage{args.stage}.npy")
    de = np.load(hyper_dir / f"de_stage{args.stage}.npy")

    # -----------------------------
    # è¯»å– metadata
    # -----------------------------
    exprs, metas, names = load_dataset_pairs(args.dataset)
    # è¯»å– cell_idï¼ˆå’Œ H è¡Œé¡ºåºä¸€è‡´ï¼‰
    X, cells, genes = load_expr_matrix(
        exp_dir / "data" / f"expr_stage{args.stage}.npz"
    )

    # ç”¨ cell_id å¯¹é½ metadataï¼ˆè¿™æ˜¯å…³é”®ï¼‰
    meta = metas[args.stage].loc[cells]


    # -----------------------------
    # æ‰§è¡Œæ£€æŸ¥
    # -----------------------------
    check_structure(H)
    check_degrees(dv, de)
    check_cell_participation(H)
    check_program_sizes(H)
    check_biological_enrichment(H, meta)

    print("\nğŸ‰ Hypergraph sanity check å®Œæˆ")


if __name__ == "__main__":
    main()
